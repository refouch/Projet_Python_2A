{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install bs4\n",
    "!pip install nbformat\n",
    "!pip install pandas\n",
    "!pip install geopandas\n",
    "!pip install requests\n",
    "!pip install --upgrade xlrd\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%run ./Tidy.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase de modélisation: tentative de prédiction de la consommation et de la légalisation\n",
    "\n",
    "Dans cette seconde phase du projet, nous allons nous appuyer sur les statistiques descriptives produites juste avant afin d'orienter nos choix de modélisation.\n",
    "\n",
    "Nous allons ici présenter les deux approches que nous avons prises. En effet, nous avions d'abord en tête avec ce projet d'essayer de prédire la légalisation ou non du cannabis dans un pays donné à partir des données mises à disposition par l'EUDA. Cette première approche s'est avérée infructueuse après de nombreux essais; et nous expliquerons les raisons de cet échec et les conclusions que nous en avons tiré dans une partie \"bonus\", à la fin de ce notebook. En effet, même si le modèle obtenu n'était pas performant, il nous a tout de même permis de tirer des conclusions intéressantes sur notre jeu de données.\n",
    "\n",
    "La principale raison pour laquelle ce premier modèle s'est avéré infructueux tenait notamment au manque de données disponibles, et au nombre restreint d'observations à notre disposition. Nous avons alors mis en place plusieurs solutions à ce problème:\n",
    "\n",
    "- En premier lieu, nous avons changé la variable à prédire. Plutôt que de se concentrer sur la législation, trop peu corrélée aux données disponibles, nous nous attacherons plutôt à tenter d'estimer la part de la consommation de cannabis dans chaque pays, en utilisant des variables socioéconomiques. Cela exige alors de changer de modèle, en abandonnant le classifieur initialement prévu à différents modèles de régression.\n",
    "\n",
    "- Ensuite, nous avons tenu à rassembler des données plus conséquentes sur chaque pays, afin d'entraîner plus finement chaque modèle. On a ainsi pu récupérer en complément des données sur la consommation de drogues, d'autres données sur les admissions à l'hôpital liées à la consommation de drogues, sur le nombre d'infractions commises liées au trafic, ou encore des données macroéconomiques simples sur chaque pays (PIB, IDH, tau de criminalité...). On espère ainsi pouvoir entraîner un modèle plus performant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Phase de préparation des données\n",
    "\n",
    "Comme à chaque fois que l'on souhaite entraîner un modèle, **il convient avant tout de préparer et nettoyer les données au préalable.** Nous effectuerons cette tâche selon le schéma suivant:\n",
    "\n",
    "1. Tout d'abord la collecte et la restriction, dans la masse de données mises à notre disposition, des seules variables qui nous intéressent réellement afin d'effectuer notre entraînement, en ignorant les variables moins intéressantes afin d'obtenir un *dataframe* clair et lisible, ne contenant aucun **NaN** ou valeur nulle.\n",
    "\n",
    "2. Ensuite la préparation de ces données, notamment la standardisation et la normalisation de celles-ci afin de pouvoir effectuer notre régression correctement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Nettoyage et restriction des données\n",
    "\n",
    "#### 1.1.1 Une fonction d'agrégation bien utile\n",
    "\n",
    "Le premier problème à régler est le suivant: dans notre jeu de données nous disposons de beaucoup de variables identiques, relevées année par année. Or il se peut dans beaucoup de cas que l'on dispose de données récentes pour certains pays, mais pas pour d'autres pour lesquels il faut remonter quelques années en arrière. Cela a pour conséquence un jeu de donnée très troué, avec beaucoup de **NaN** dont on aimerait se débarrasser.\n",
    "\n",
    "Afin de limiter au maximum le nombre de données vides, **on se décide alors à ne garder pour chaque pays que les données les plus récentes disponibles**. Cela nous permet de minimiser le nombre de valeurs manquantes puisqu'au lieu de ne considérer que l'année ou il y a le moins de trous, on écrase toute les années en ne gardant que la donnée la plus récente (ce qui soit dit en passant a tout de même un sens; utiliser le chiffre le plus récent semble plus raisonnable que de choisir arbitrairement l'année pour laquelle on a le plus de données)\n",
    "\n",
    "Cela est implémenté par une simple fonction, qui fonctionne sur notre structure de donnée définie au préalable (pour plus d'informations, se référer à la deuxième partie du Notebook `Tidy.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_data(df, new_df, variable):\n",
    "    \"\"\" Parcours la table pour créer une nouvelle variable qui prend en compte les données les plus récentes disponibles\n",
    "        Ce afin de pallier aux fait qu'on manque de données récentes pour certaines variables\"\"\"\n",
    "\n",
    "    columns = list(df.columns.values)\n",
    "    good_col = []\n",
    "\n",
    "    new_df['Country'] = df['Country']\n",
    "\n",
    "    for i in range(len(columns)):\n",
    "        if variable in columns[i]:\n",
    "            good_col.append(columns[i])\n",
    "\n",
    "    for index in df.index:\n",
    "        for column in good_col:\n",
    "            if pd.isna(df.at[index, column]) == False:\n",
    "                new_df.at[index, variable] = df.at[index, column]\n",
    "                break\n",
    "\n",
    "    new_df.dropna(inplace = True)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. BONUS: Une première idée rejetée\n",
    "\n",
    "Nous avons en premier lieu essayé de prédire la légalisation ou non du cannabis au sein d'un même pays à l'aide d'un SVM prenant en entrée la prévalence dans chaque pays.\n",
    "\n",
    "Cette première approche n'a pas porté les fruits escomptés et ce pour plusieurs raisons, la principale étant une inadéquation entre notre jeu de données (trop faible) et le modèle choisi. Cette dernière section nous permet d'illustrer les raisons de cet échec et de tirer des conclusions sur la démarche à adopter lors du choix et de la mise en place de modèles.\n",
    "\n",
    "### 3.1 Premier entraînement du classifieur sur des données de prévalence\n",
    "\n",
    "On s'était d'abord restreint dans le cadre de la prédiction de la légalisation ou non du cannabis dans chaque pays, au pourcentage d'individus ayant déjà consommé du cannabis dans leur vie pour chaque pays.\n",
    "On se rend alors vite compte que cette restriction nous donne un jeu de données très faible (1 observation par pays, soit seulement 29 observations). Ce qui va poser problème par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# On récupère la table de légalisation que l'on a nettoyé en amont\n",
    "\n",
    "legal = legal_pays_clean\n",
    "\n",
    "# On prend la prévalence sur la vie entière\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/refouch/Projet_Python_2A/refs/heads/main/Data/EUDA/edr2024-gps-current-table-1.csv')\n",
    "\n",
    "dfcurrent = df[df['Substance'] == 'Cannabis']\n",
    "\n",
    "dfcurrentadults = dfcurrent[dfcurrent['Age'] == 'All adults (15-64)']\n",
    "\n",
    "dfcurrentadultslf = dfcurrentadults[dfcurrentadults['Recall period'] == 'Lifetime']\n",
    "\n",
    "# On effectue un merge les deux tables\n",
    "dfadultslf_legal = dfcurrentadultslf.join(legal, on = 'Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a ensuite mis en place notre classifieur de manière classique, en utilisant les fonctions déjà fournies par ScikitLearn. Quelques remarques cependant sur la construction de notre modèle:\n",
    "\n",
    "- On choisit de recoder les variables catégorielles sur la légalité en une variable binaire: 0 si le cannabis est Illegal, 1 si il est Légalisé ou Décriminalisé. Après plusieurs test en effet, nous avons conclu qu'il était préférable de se limiter à une variable binaire et de ne pas marquer la spécificité de la décriminalisation, notre jeu de données étant déjà suffisamment restreint.\n",
    "\n",
    "- On choisit de diviser nos données de manière assez classique, en gardant un échantillon de 20% pour tester notre modèle tout en gardant 80% pour l'entraînant. Cela pose déjà un problème puisque cela ne laisse en soi que 6 observations sur lesquelles tester notre modèle, et 22 sur lesquelles l'entraîner. Ce qui amènera par la suite de fortes disparités d'une phase d'entraînement à l'autre.\n",
    "\n",
    "- Pour notre premier essai, nous tentons simplement de fournir à notre modèle la prévalence sur la vie entière (i.e le pourcentage d'individus par pays ayant déjà fumé du cannabis dans sa vie), ainsi que la prévalence en fonction du sexe. Cela s'avèrera évidemment insuffisant, mais cela nous permettra par la suite d'illustrer au mieux les problèmes rencontrés et d'appuyer les conclusions que nous en avons tiré. Ces données on en outre le bon goût d'être de simples pourcentages, ce qui ne permet de ne pas avoir à les normaliser au préalable, ni d'avoir a se soucier d'éventuels outliers.\n",
    "\n",
    "\n",
    "Ceci étant dit, nous pouvons passer à la phase d'entraînement du modèle. **Nous allons ainsi l'entraîner deux fois en prenant à chaque fois une *seed* différente** ce qui va nous permettre de démontrer l'inconstance de notre modèle, et finalement sa faible utilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle après entraînement sur le premier découpage:  0.16666666666666666\n",
      "Précision du modèle après entraînement sur le second découpage:  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Recodage des variables catégorielles et division de notre échantillon\n",
    "\n",
    "dfadultslf_legal['Recreational_num'] = dfadultslf_legal['Recreational'].replace({'Decriminalized' : 2, 'Legal' : 1, 'Illegal' : 0})\n",
    "dfadultslf_legal['Medical_num'] = dfadultslf_legal['Medical'].replace({'Decriminalized' : 2, 'Legal' : 1, 'Illegal' : 0})\n",
    "\n",
    "X = dfadultslf_legal[['Prevalence (%)','Males (%)','Females (%)']]\n",
    "Y = dfadultslf_legal['Recreational_num']\n",
    "\n",
    "# Création de deux échantillonages différents, selon une seed prédéterminée\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=1241)\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X,Y, test_size=0.2, random_state=76835790)\n",
    "\n",
    "# Entraînement du classifieur sur nos deux échantillonages\n",
    "svm_classifier = svm.SVC(C=1, kernel='linear')\n",
    "\n",
    "svm_classifier.fit(X_train, Y_train)\n",
    "Y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "svm_classifier.fit(X2_train, Y2_train)\n",
    "Y2_pred = svm_classifier.predict(X2_test)\n",
    "\n",
    "# Accuracy score \n",
    "accuracy_score = sklearn.metrics.accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "accuracy_score_2 = sklearn.metrics.accuracy_score(Y2_test, Y2_pred)\n",
    "\n",
    "print('Précision du modèle après entraînement sur le premier découpage: ', accuracy_score)\n",
    "print('Précision du modèle après entraînement sur le second découpage: ', accuracy_score_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque donc qu'en fonction de notre découpage, la précision du modèle peut s'avérer une fois très bonne, et une autre fois absolument médiocre. De cela on ne peut conclure qu'une seule chose: notre modèle prédit essentiellement au hasard (ici les deux seed ont été bien choisies pour illustrer notre démarche, mais dans la plupart des test réalisés on se retrouvait avec une *accuracy* oscillant autour de 0.5, soit l'espérance de prédire correctement une variable binaire au hasard)\n",
    "\n",
    "Ainsi, la variable utilisée pour l'entraîner n'a qu'un pouvoir explicatif très faible sur celle que l'on cherche à prédire.\n",
    "Autrement dit: la prévalence de la consommation du cannabis dans chaque pays n'est que très faiblement (voire pas du tout) corrélée à l'état de la législation dans ce pays. On pouvait en réalité déjà s'en rendre compte lors de la phase de statistiques descriptives: si la consommation de cannabis est illégale en France comme en Turquie, ces deux pays constituent les valeurs extrêmes de notre échantillon quand à la prévalence sur la vie entière (56% contre 2%)\n",
    "\n",
    "Il devient alors évident **qu'il nous faut plus de données, et des données plus pertinentes afin d'établir un classifieur plus performant**. C'est ce que nous avons tenté de faire par la suite, et ce qui nous a posé encore d'autres problèmes, desquels nous pouvons tirer encore d'autres conclusions intéréssantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Second entraînement du classifieur, cette fois sur des données judiciaires\n",
    "\n",
    "Notre principal problème étant le manque de corrélation entre nos variables explicatives et notre variable à prédire, nous sommes allé chercher des données de l'EUDA qui pourrait le mieux expliquer la légalisation ou non du cannabis dans un pays donné.\n",
    "\n",
    "On s'est alors arrêté sur les données judiciaires fournies par l'agence, à savoir le nombre d'infractions commises dans chaque pays concernant la consommation, la vente, ou encore la production de cannabis.\n",
    "On imagine a priori que ces nouvelles données nous permettrons de mieux prédire la légalisation ou non du cannabis dans un pays donné.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>cannabis.conso_x</th>\n",
       "      <th>cannabis.conso_y</th>\n",
       "      <th>cannabis.prod</th>\n",
       "      <th>cannabis.ventes</th>\n",
       "      <th>Recreational</th>\n",
       "      <th>Medical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>19909.0</td>\n",
       "      <td>19909.0</td>\n",
       "      <td>2601.0</td>\n",
       "      <td>6784.0</td>\n",
       "      <td>Decriminalized</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>29572.0</td>\n",
       "      <td>29572.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>Decriminalized</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>5159.0</td>\n",
       "      <td>5159.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>Decriminalized</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>563.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>Illegal</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Czechia</td>\n",
       "      <td>6443.0</td>\n",
       "      <td>6443.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>Decriminalized</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Germany</td>\n",
       "      <td>174876.0</td>\n",
       "      <td>174876.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>39366.0</td>\n",
       "      <td>Legal</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Greece</td>\n",
       "      <td>5764.0</td>\n",
       "      <td>5764.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>3601.0</td>\n",
       "      <td>Illegal</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hungary</td>\n",
       "      <td>3437.0</td>\n",
       "      <td>3437.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>Illegal</td>\n",
       "      <td>Illegal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>2245.0</td>\n",
       "      <td>2245.0</td>\n",
       "      <td>Decriminalized</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>6112.0</td>\n",
       "      <td>Decriminalized</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Slovakia</td>\n",
       "      <td>288.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>Illegal</td>\n",
       "      <td>Illegal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Spain</td>\n",
       "      <td>323055.0</td>\n",
       "      <td>323055.0</td>\n",
       "      <td>3021.0</td>\n",
       "      <td>17884.0</td>\n",
       "      <td>Decriminalized</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Türkiye</td>\n",
       "      <td>62782.0</td>\n",
       "      <td>62782.0</td>\n",
       "      <td>5725.0</td>\n",
       "      <td>16167.0</td>\n",
       "      <td>Illegal</td>\n",
       "      <td>Legal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country  cannabis.conso_x  cannabis.conso_y  cannabis.prod  \\\n",
       "0       Austria           19909.0           19909.0         2601.0   \n",
       "1       Belgium           29572.0           29572.0          661.0   \n",
       "3       Croatia            5159.0            5159.0          252.0   \n",
       "4        Cyprus             563.0             563.0           18.0   \n",
       "5       Czechia            6443.0            6443.0          184.0   \n",
       "10      Germany          174876.0          174876.0          494.0   \n",
       "11       Greece            5764.0            5764.0          537.0   \n",
       "12      Hungary            3437.0            3437.0          117.0   \n",
       "19  Netherlands            2413.0            2413.0         2245.0   \n",
       "22     Portugal            7020.0            7020.0          247.0   \n",
       "24     Slovakia             288.0             288.0            4.0   \n",
       "26        Spain          323055.0          323055.0         3021.0   \n",
       "28      Türkiye           62782.0           62782.0         5725.0   \n",
       "\n",
       "    cannabis.ventes    Recreational  Medical  \n",
       "0            6784.0  Decriminalized    Legal  \n",
       "1            5805.0  Decriminalized    Legal  \n",
       "3            1016.0  Decriminalized    Legal  \n",
       "4             166.0         Illegal    Legal  \n",
       "5             728.0  Decriminalized    Legal  \n",
       "10          39366.0           Legal    Legal  \n",
       "11           3601.0         Illegal    Legal  \n",
       "12            587.0         Illegal  Illegal  \n",
       "19           2245.0  Decriminalized    Legal  \n",
       "22           6112.0  Decriminalized    Legal  \n",
       "24            267.0         Illegal  Illegal  \n",
       "26          17884.0  Decriminalized    Legal  \n",
       "28          16167.0         Illegal    Legal  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# On récupère la table de légalisation que l'on a nettoyé en amont\n",
    "\n",
    "legal = legal_pays_clean\n",
    "\n",
    "# On prend cette fois les données judiciaires, qu'on passe par notre fonction de tri définie en amont\n",
    "\n",
    "dfcurrent = table_infractions_legales\n",
    "\n",
    "df_infrac = pd.DataFrame()\n",
    "\n",
    "df_infrac = get_latest_data(dfcurrent,df_infrac,'cannabis.conso_x')\n",
    "df_infrac = get_latest_data(dfcurrent,df_infrac,'cannabis.conso_y')\n",
    "df_infrac = get_latest_data(dfcurrent,df_infrac,'cannabis.prod')\n",
    "df_infrac = get_latest_data(dfcurrent,df_infrac,'cannabis.ventes')\n",
    "\n",
    "\n",
    "#On effectue un merge les deux tables\n",
    "df_infrac_legal = df_infrac.join(legal, on = 'Country')\n",
    "\n",
    "df_infrac_legal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit déjà apparaître ici notre principal problème: à force d'écarter les lignes qui comportent des valeurs manquantes pour une seule des variables que l'on veut inclure, on se retrouve avec un jeu de données très restreint. C'est une situation particulièrement difficile puisque nous ne pouvons pas y faire grand chose, cela tient uniquement à l'absence de données fournies par l'EUDA pour beaucoup de pays.\n",
    "\n",
    "On tentera tout de même d'entraîner notre modèle, mais en s'attendant à des résultats tout au plus médiocres.\n",
    "\n",
    "**NOTE**: contrairement à notre premier entraînement du modèle, il nous est ici nécessaire de normaliser nos données pour chaque variable car les ordres de grandeurs peuvent varier d'une infraction à l'autre. Cela a donc été implémenté dans le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle:  0.6666666666666666\n",
      "Taille de l'échantillon de test:  3\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Recodage des variables catégorielles\n",
    "\n",
    "df_infrac_legal['Recreational_num'] = df_infrac_legal['Recreational'].replace({'Decriminalized' : 1, 'Legal' : 1, 'Illegal' : 0})\n",
    "df_infrac_legal['Medical_num'] = df_infrac_legal['Medical'].replace({'Decriminalized' : 1, 'Legal' : 1, 'Illegal' : 0})\n",
    "\n",
    "X = df_infrac_legal[['cannabis.conso_x','cannabis.conso_y','cannabis.prod','cannabis.ventes']]\n",
    "Y = df_infrac_legal['Recreational_num']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=3)\n",
    "\n",
    "X_train = preprocessing.normalize(X_train)\n",
    "X_test = preprocessing.normalize(X_test)\n",
    "\n",
    "svm_classifier = svm.SVC(C=1, kernel='linear')\n",
    "\n",
    "svm_classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "accuracy_score = sklearn.metrics.accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print('Précision du modèle: ', accuracy_score)\n",
    "print(\"Taille de l'échantillon de test: \", len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se retrouve le plus souvent avec un score de précision aux alentour de 0.66, ce qui est donc en soi un peu meilleur qu'une simple prédiction aléatoire. Cependant, il nous est impossible de tirer quoique ce soit de ce score puisque rappelons qu'il est calculé ainsi:\n",
    "\n",
    "$Accuracy = \\dfrac{VP + VN}{FP + FN + VP + VN}$\n",
    "\n",
    "Avec VP les vrais positifs, FP les faux positifs, etc.\n",
    "Autrement dit, le nombre de prédictions correctes divisées par la population totale de l'échantillon de test. Ici puisque la taille de l'échantillon de test est seulement de 3 observations, il est en réalité difficile d'inférer quoique ce soit de ce ratio. La taille de l'échantillon est donc définitivement trop faible pour que l'on puisse tirer des conclusions satisfaisantes de notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Conclusions générales tirés de cet échec\n",
    "\n",
    "On se rend donc finalement compte d'un problème général et plutôt flagrant qui frappe le jeu de données choisi: ce dernier comporte un nombre beaucoup trop faible d'observations pour tenter de faire de l'apprentissage supervisé comme nous aurions aimé le faire.\n",
    "\n",
    "La nature même de notre sujet, qui se limite à 29 pays membres de l'Union Européenne, rend donc bien difficile la mise en place de modèles de machine learning afin de produire des prédictions satisfaisantes et des analyses pertinentes. \n",
    "\n",
    "Des pistes à explorer si l'on voulait tout de même essayer de prédire l'état de la législation dans un pays donné serait alors éventuellement de ne tenter de prédire que la législation d'un seul pays, en connaissant celle des autres pays qui présenteraient des caractéristiques similaires au pays dont on essaierait de prédire la législation. \n",
    "\n",
    "Par manque de temps et de moyens, ce n'est pas le chemin que nous avons choisi de suivre. Fort des enseignements tirés de cet échec, nous nous sommes plutôt tournés vers la mise en place de modèle qui semblent plus adaptés au jeu de données mis à notre disposition. En effet, étant donné que nous possédons un nombre très limités d'individus (les pays), mais d'énormément de variables et d'observation pour chacun de ses individus, il nous paraît alors plus pertinent de nous tourner vers des modèles de régression linaires, qui seront plus propice à prédire et expliquer d'autres variables que la législation. Nous avons donc tenté, après cela, de nous tourner vers une prédiction de la consommation.\n",
    "\n",
    "A TERMINER UNE FOIS LE PREMIER MODELE MIS EN PLACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression logistique sur les même variables juste pour essayer de voir si c'est mieux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=16)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "accuracy = sklearn.metrics.accuracy_score(Y_pred,Y_test)\n",
    "\n",
    "print(accuracy)\n",
    "#accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
